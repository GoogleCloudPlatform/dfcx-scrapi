{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vertex Agent Builder and Dialogflow CX Evaluations\n",
    "In this notebook, we will show you how to:\n",
    "1. Build a new Evaluation Dataset for your Agent.\n",
    "2. Run the Evaluations to get Quality Metrics\n",
    "3. Push the Results to Google Sheets for reporting.\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "- Existing Agent Builder or DFCX Agent w/ or w/out Tool calling.\n",
    "<br>\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/dfcx-scrapi/blob/main/examples/vertex_ai_conversation/vertex_agents_evals.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/dfcx-scrapi/blob/main/examples/vertex_ai_conversation/vertex_agents_evals.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/dfcx-scrapi/blob/main/examples/vertex_ai_conversation/vertex_agents_evals.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dfcx-scrapi>=1.12.0\n",
    "\n",
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "    from google.auth import default\n",
    "\n",
    "    auth.authenticate_user()\n",
    "    credentials, _ = default()\n",
    "else:\n",
    "    # Otherwise, attempt to discover local credentials as described in\n",
    "    # https://cloud.google.com/docs/authentication/application-default-credentials\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Dataset Format\n",
    "\n",
    "Collecting and evaluating multi-turn chat data can be complex, so we have devised template that you can follow to make it easy and scalable.\n",
    "\n",
    "The evaluation dataset must be in a tabular format and contain the following columns:\n",
    "- `eval_id` \n",
    "  - _Unique identifier of a conversation, which must be the same for each row that is part of the same conversation_\n",
    "- `action_id` \n",
    "  - _Index of the specific action for the current conversation._\n",
    "  - _This is used to track and pair responses during inference time._\n",
    "- `action_type` \n",
    "  - _The specific action for this turn._\n",
    "  - _There are currently 4 supported Action Types: `User Utterance`, `Agent Response`, `Playbook Invocation`, `Tool Invocation`_\n",
    "- `action_input`\n",
    "  - _The input for this specific action_type._\n",
    "  - _Based on the specified action_type, this could be the expected user utterance or agent response, the expected Playbook name, or the expected Tool name._\n",
    "- `action_input_parameters`\n",
    "  - When `Playbook Invocation` or `Tool Invocation` is selected as the `action_type`, this refers to the payload of information that is expected to be sent with that invocation._\n",
    "  - _For example, a JSON payload of key/value pairs called with the tool._\n",
    "- `tool_action`\n",
    "  - _This field is only used when `Tool Invocation` is chosen as the `action_type`._\n",
    "  - _This allows us to run evaluations on whether the Tool call chose the correct internal action (if more than one exists)_\n",
    "\n",
    "---\n",
    "\n",
    "An example for the queryset can be seen in this table:\n",
    "\n",
    "| eval_id | action_id | action_type | action_input | action_input_parameters | tool_action | notes |\n",
    "|---|---|---|---|---|---|---|\n",
    "| travel-ai-001 | 1 | User Utterance | Paris |  |  |  |\n",
    "| travel-ai-001 | 2 | Playbook Invocation | Travel Inspiration |  |  |  |\n",
    "| travel-ai-001 | 3 | Agent Response | Paris is a beautiful city! Here are a few things you might enjoy doing there:<br><br>Visit the Eiffel Tower<br>Take a walk along the Champs-Élysées<br>Visit the Louvre Museum<br>See the Arc de Triomphe<br>Take a boat ride on the Seine River |  |  |  |\n",
    "| travel-ai-002 | 1 | User Utterance | I want to go to Barcelona with my family of four in June |  |  |  |\n",
    "| travel-ai-002 | 2 | Playbook Invocation | Travel Inspiration |  |  |  |\n",
    "| travel-ai-002 | 3 | Agent Response | I'd be happy to help you find a hotel in Barcelona for your family of four in June. What are your preferred dates of travel? |  |  |  |\n",
    "| travel-ai-002 | 4 | User Utterance | 1st through 10th |  |  |  |\n",
    "| travel-ai-002 | 5 | Playbook Invocation | Book Hotel |  |  |  |\n",
    "| travel-ai-002 | 6 | Tool Invocation | hotel_tool | {'city': 'Barcelona', 'num_results': 10} | hotel_search |  |\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "The preferred method for data loading is to use Google Sheets.  \n",
    "However you can also manually build your dataset as a Pandas Dataframe, or load from CSV, BQ, etc. as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1 - From Google Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dfcx_scrapi.tools.evaluations import DataLoader\n",
    "\n",
    "data = DataLoader()\n",
    "\n",
    "sheet_name = \"[TEMPLATE] Vertex Agent Evals Dataset Format\"\n",
    "sheet_tab = \"golden-agent-evals\"\n",
    "\n",
    "sample_df = data.from_google_sheets(sheet_name, sheet_tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2 - From Local CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dfcx_scrapi.tools.evaluations import DataLoader\n",
    "\n",
    "data = DataLoader()\n",
    "\n",
    "csv_file_path = \"\"\n",
    "\n",
    "sample_df = data.from_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 3 - Manual Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dfcx_scrapi.tools.evaluations import DataLoader\n",
    "\n",
    "data = DataLoader()\n",
    "\n",
    "INPUT_SCHEMA_REQUIRED_COLUMNS = ['eval_id', 'action_id', 'action_type', 'action_input', 'action_input_parameters', 'tool_action', 'notes']\n",
    "\n",
    "sample_df = pd.DataFrame(columns=INPUT_SCHEMA_REQUIRED_COLUMNS)\n",
    "\n",
    "sample_df.loc[0] = [\"travel-ai-001\", 1, \"User Utterance\", \"Paris\", \"\", \"\", \"\"]\n",
    "sample_df.loc[1] = [\"travel-ai-001\", 2, \"Playbook Invocation\", \"Travel Inspiration\", \"\", \"\", \"\"]\n",
    "sample_df.loc[2] = [\"travel-ai-001\", 3, \"Agent Response\", \"Paris is a beautiful city! Here are a few things you might enjoy doing there:\\n\\nVisit the Eiffel Tower\\nTake a walk along the Champs-Élysées\\nVisit the Louvre Museum\\nSee the Arc de Triomphe\\nTake a boat ride on the Seine River\", \"\", \"\", \"\"]\n",
    "\n",
    "sample_df = data.from_dataframe(sample_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "For multi-turn chat Agents w/ or w/out tool calling, there are currently 2 metrics supported:\n",
    "1. `Response Similarity`, this performs a Semantic Similarity comparison between the expected \"golden\" response and the actual \"predicted\" response\n",
    "2. `Tool Call Quality`, this performs and EXACT_MATCH on 2 components of the Tool call\n",
    "    - Tool Name, i.e. was the correct Tool invoked\n",
    "    - Tool Action, i.e. for the given Tool, was the correct Action / Endpoint invoked\n",
    "\n",
    "Other metrics like `UrlMatch`, `Faithfulness`, `Answer Correctness`, `Context Recall` etc. will be supported in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dfcx_scrapi.tools.evaluations import Evaluations\n",
    "\n",
    "# [1] Define your Agent ID here\n",
    "agent_id = \"projects/your-project/locations/us-central1/agents/11111-2222-33333-44444\" # Example Agent\n",
    "\n",
    "# [2] Instantiate Evals class w/ Metrics\n",
    "evals = Evaluations(agent_id, metrics=[\"response_similarity\", \"tool_call_quality\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and Evaluate\n",
    "In this step, we will run all of the queries against the Agent that is being evaluated.  \n",
    "Once the queries are returned, we will then compute all of the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = evals.run_query_and_eval(sample_df.head(10))\n",
    "\n",
    "print(f\"Average Similarity {eval_results.similarity.mean()}\")\n",
    "print(f\"Average Tool Call Quality {eval_results.tool_name_match.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can inspect the results as needed\n",
    "eval_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to Google Sheets\n",
    "Storing the evaluation results to Google Sheets can be done with the following snippets.\n",
    "\n",
    "In future revisions, we will add export to other format including `csv`, `bigquery`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dfcx_scrapi.tools.evaluations import DataLoader\n",
    "\n",
    "data = DataLoader()\n",
    "\n",
    "data.write_eval_results_to_sheets(eval_results, sheet_name, results_tab=\"latest_results\")\n",
    "data.append_test_results_to_sheets(eval_results, sheet_name, summary_tab=\"reporting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ending and Wrap-Up\n",
    "\n",
    "In this notebook, we've shown how to programmatically Evaluate your Agent Builder or Dialogflow CX Agent.\n",
    "\n",
    "For more information, see:\n",
    "- [Vertex AI Agents](https://cloud.google.com/dialogflow/vertex/docs/concept/agents)\n",
    "- [Dialogflow CX](https://cloud.google.com/dialogflow/cx/docs)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19fe958eff886c70bc7b0837ba1e6b09536c8944c54196036e51b6ba767223fc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('scrapi-local': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
